from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
import time
from bs4 import BeautifulSoup
import json
import os

def crawl_google_maps(query, scroll_times=3, wait_time=2):
    driver = webdriver.Chrome()
    driver.get("https://www.google.com/maps")
    time.sleep(3)

    # Nháº­p tÃ¬m kiáº¿m
    search_box = driver.find_element(By.ID, "searchboxinput")
    search_box.send_keys(query)
    search_box.send_keys(Keys.ENTER)
    time.sleep(5)

    # Cuá»™n xuá»‘ng Ä‘á»ƒ load thÃªm káº¿t quáº£
    for _ in range(scroll_times):
        driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.END)
        time.sleep(wait_time)

    # Parse HTML
    soup = BeautifulSoup(driver.page_source, "html.parser")
    results = soup.find_all('div', class_='Nv2PK')
    print(f"ğŸ” TÃ¬m tháº¥y {len(results)} káº¿t quáº£ cho: {query}")

    data = []

    for r in results:
        try:
            link_tag = r.find('a', class_='hfpxzc')
            if link_tag:
                raw_name = link_tag.get('aria-label', '').strip()
                name = raw_name.split('Â·')[0].strip() if raw_name else 'N/A'
                link = link_tag.get('href', 'N/A')
            else:
                name = 'N/A'
                link = 'N/A'

            address_tag = r.find('div', class_='rllt__details')
            address = address_tag.get_text(strip=True) if address_tag else 'N/A'

            rating_tag = r.find('span', class_='MW4etd')
            rating = rating_tag.get_text(strip=True) if rating_tag else 'N/A'

            item = {
                "name": name,
                "address": address,
                "rating": rating,
                "link": link
            }
            data.append(item)
        except Exception as e:
            print(f"âŒ Lá»—i khi parse 1 káº¿t quáº£: {e}")

    driver.quit()
    return data

if __name__ == "__main__":
    os.makedirs("data", exist_ok=True)
    while True:
        query = input("ğŸ” Nháº­p tá»« khoÃ¡ tÃ¬m kiáº¿m (hoáº·c nháº­p 0 Ä‘á»ƒ thoÃ¡t): ").strip()
        if query == "0":
            print("ğŸ‘‹ Káº¿t thÃºc!")
            break

        print(f"ğŸš€ Äang crawl dá»¯ liá»‡u cho: {query}")
        data = crawl_google_maps(query)

        # Táº¡o tÃªn file tá»« tá»« khoÃ¡: thay khoáº£ng tráº¯ng thÃ nh _
        safe_filename = query.replace(' ', '_') + ".json"
        filepath = os.path.join("data", safe_filename)

        # LÆ°u file
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        print(f"âœ… ÄÃ£ lÆ°u káº¿t quáº£ vÃ o {filepath}")
